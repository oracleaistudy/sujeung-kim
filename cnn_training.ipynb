{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be9b3ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6412 1579 2024\n",
      "train malignant ratio: 0.19915782907049281\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "BASE = Path(\".\")\n",
    "META = BASE / \"HAM10000_metadata.csv\"\n",
    "IMG_DIR = BASE / \"image\"\n",
    "\n",
    "df = pd.read_csv(META)\n",
    "\n",
    "# 1) ì´ì§„ ë¼ë²¨ (ì•…ì„±=1)\n",
    "malignant = [\"mel\", \"bcc\", \"akiec\"]\n",
    "df[\"target\"] = df[\"dx\"].isin(malignant).astype(int)\n",
    "\n",
    "# 2) ì´ë¯¸ì§€ ê²½ë¡œ ìƒì„± + íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "df[\"image_path\"] = df[\"image_id\"].apply(lambda x: str(IMG_DIR / f\"{x}.jpg\"))\n",
    "df = df[df[\"image_path\"].apply(lambda p: Path(p).exists())].reset_index(drop=True)\n",
    "\n",
    "# 3) lesion_id ê¸°ì¤€ ê·¸ë£¹ split (ëˆ„ìˆ˜ ë°©ì§€)\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(df, df[\"target\"], groups=df[\"lesion_id\"]))\n",
    "train_df, test_df = df.iloc[train_idx].copy(), df.iloc[test_idx].copy()\n",
    "\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)  # trainì—ì„œ val ë¶„ë¦¬\n",
    "tr_idx, val_idx = next(gss2.split(train_df, train_df[\"target\"], groups=train_df[\"lesion_id\"]))\n",
    "tr_df, val_df = train_df.iloc[tr_idx].copy(), train_df.iloc[val_idx].copy()\n",
    "\n",
    "print(len(tr_df), len(val_df), len(test_df))\n",
    "print(\"train malignant ratio:\", tr_df[\"target\"].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9589859",
   "metadata": {},
   "source": [
    "ë©”íƒ€ë°ì´í„°ì—ì„œ ë¼ë²¨ ë§Œë“¤ê¸°\n",
    "\n",
    "6412 : train set(í•™ìŠµìš© ì´ë¯¸ì§€ ìˆ˜)\n",
    "1579 : validation set(ê²€ì¦ìš© ì´ë¯¸ì§€ ìˆ˜)\n",
    "2024 : test set(ìµœì¢… í‰ê°€ìš© ì´ë¯¸ì§€ ìˆ˜)\n",
    "ì•…ì„±ë¹„ìœ¨ : 19%\n",
    "\n",
    "- ë¹„ì–´ìˆëŠ” ë°ì´í„° ì—†ìŒ\n",
    "\n",
    "Lesion-level ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¶„í• í•œ ê²°ê³¼,\n",
    "í•™ìŠµÂ·ê²€ì¦Â·í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ê°€ ì•ˆì •ì ìœ¼ë¡œ êµ¬ì„±ë˜ì—ˆìœ¼ë©°,\n",
    "í•™ìŠµ ì„¸íŠ¸ ë‚´ ì•…ì„± ë¹„ìœ¨ì€ ì•½ 20%ë¡œ\n",
    "ì‹¤ì œ ì„ìƒ ë°ì´í„°ì˜ ë¶ˆê· í˜• íŠ¹ì„±ì„ ìœ ì§€í•˜ì˜€ë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea4ee97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df: (10015, 9)\n",
      "malignant ratio: 0.19510733899151272\n",
      "sizes: 6412 1579 2024\n",
      "train malignant ratio: 0.19915782907049281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 09:06:58.810744: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-12-17 09:06:58.811635: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… train_ds / val_ds / test_ds created!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import tensorflow as tf\n",
    "\n",
    "# =========================\n",
    "# 1) ê²½ë¡œ ì„¤ì • (ì—¬ê¸°ë§Œ ìˆ˜ì •)\n",
    "# =========================\n",
    "META_PATH = Path(\"HAM10000_metadata.csv\")\n",
    "IMG_DIR = Path(\"image\")  # ì˜ˆ: Path(\"HAM10000_images\") / Path(\"HAM10000_images_part_1\") ë“±\n",
    "\n",
    "# =========================\n",
    "# 2) ë©”íƒ€ë°ì´í„° ë¡œë“œ + ë¼ë²¨ ìƒì„±\n",
    "# =========================\n",
    "df = pd.read_csv(META_PATH)\n",
    "\n",
    "malignant = [\"mel\", \"bcc\", \"akiec\"]\n",
    "df[\"target\"] = df[\"dx\"].isin(malignant).astype(int)\n",
    "\n",
    "# ì´ë¯¸ì§€ ê²½ë¡œ ìƒì„±\n",
    "df[\"image_path\"] = df[\"image_id\"].apply(lambda x: str(IMG_DIR / f\"{x}.jpg\"))\n",
    "\n",
    "# ì‹¤ì œ íŒŒì¼ ì¡´ì¬í•˜ëŠ” ê²ƒë§Œ ë‚¨ê¸°ê¸° (ê²½ë¡œ í‹€ë¦¬ë©´ ì—¬ê¸°ì„œ 0ê°œ ë¨)\n",
    "df = df[df[\"image_path\"].apply(lambda p: Path(p).exists())].reset_index(drop=True)\n",
    "\n",
    "print(\"df:\", df.shape)\n",
    "print(\"malignant ratio:\", df[\"target\"].mean())\n",
    "\n",
    "# =========================\n",
    "# 3) lesion_id ê¸°ì¤€ìœ¼ë¡œ train/val/test ë¶„í•  (ëˆ„ìˆ˜ ë°©ì§€)\n",
    "# =========================\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(df, df[\"target\"], groups=df[\"lesion_id\"]))\n",
    "train_df, test_df = df.iloc[train_idx].copy(), df.iloc[test_idx].copy()\n",
    "\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "tr_idx, val_idx = next(gss2.split(train_df, train_df[\"target\"], groups=train_df[\"lesion_id\"]))\n",
    "tr_df, val_df = train_df.iloc[tr_idx].copy(), train_df.iloc[val_idx].copy()\n",
    "\n",
    "print(\"sizes:\", len(tr_df), len(val_df), len(test_df))\n",
    "print(\"train malignant ratio:\", tr_df[\"target\"].mean())\n",
    "\n",
    "# =========================\n",
    "# 4) tf.data ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ë§Œë“¤ê¸°\n",
    "# =========================\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH = 32\n",
    "\n",
    "def decode_resize(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32)  # floatë¡œ ë³€í™˜\n",
    "    return img, label\n",
    "\n",
    "augment = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.05),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "def make_ds(df_part, training=False):\n",
    "    paths = df_part[\"image_path\"].values\n",
    "    labels = df_part[\"target\"].values.astype(\"int32\")\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if training:\n",
    "        ds = ds.shuffle(2048, seed=42, reshuffle_each_iteration=True)\n",
    "\n",
    "    ds = ds.map(decode_resize, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    if training:\n",
    "        ds = ds.map(lambda x, y: (augment(x, training=True), y),\n",
    "                    num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    ds = ds.batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_ds(tr_df, training=True)\n",
    "val_ds   = make_ds(val_df, training=False)\n",
    "test_ds  = make_ds(test_df, training=False)\n",
    "\n",
    "print(\"âœ… train_ds / val_ds / test_ds created!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc6c2c9",
   "metadata": {},
   "source": [
    "decode_resize(path, label)\n",
    "ì—­í• : â€œíŒŒì¼ ê²½ë¡œ â†’ ì´ë¯¸ì§€ í…ì„œë¡œ ì½ì–´ì„œ â†’ ë¦¬ì‚¬ì´ì¦ˆâ€\n",
    "\n",
    "tf.io.read_file(path)\n",
    "ë””ìŠ¤í¬ì—ì„œ íŒŒì¼ì„ â€œë°”ì´ë„ˆë¦¬â€ë¡œ ì½ìŒ (ì•„ì§ ì´ë¯¸ì§€ëŠ” ì•„ë‹˜)\n",
    "\n",
    "tf.image.decode_jpeg(..., channels=3)\n",
    "JPEG ë°”ì´ë„ˆë¦¬ë¥¼ RGB ì´ë¯¸ì§€ í…ì„œë¡œ ë””ì½”ë”©\n",
    "\n",
    "channels=3ì€ í•­ìƒ 3ì±„ë„(RGB) ê³ ì •ì´ë¼ ëª¨ë¸ ì…ë ¥ í˜•íƒœê°€ ì•ˆì •ì \n",
    "\n",
    "tf.image.resize(img, IMG_SIZE)\n",
    "í¬ê¸° í†µì¼. (ëª¨ë¸ ì…ë ¥ shape ë§ì¶”ëŠ” í•µì‹¬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5816d466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lambda (Lambda)             (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " efficientnetb0 (Functional)  (None, 7, 7, 1280)       4049571   \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,050,852\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "base = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
    "base.trainable = False  # 1ë‹¨ê³„: í—¤ë“œë§Œ í•™ìŠµ\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input((224,224,3)),\n",
    "    layers.Lambda(preprocess_input),\n",
    "    base,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fd5b26",
   "metadata": {},
   "source": [
    "layer : ëª¨ë¸ì„ êµ¬ì„±í•˜ëŠ” ì¸µ ì´ë¦„ê³¼ ì¢…ë¥˜\n",
    "output shape : í•´ë‹¹ ë ˆì´ì–´ë¥¼ ì§€ë‚˜ê³  ì˜¤ëŠ” ë°ì´í„°ì˜ ëª¨ì–‘\n",
    "param # : í•™ìŠµ íŒŒë¼ë¯¸í„°(ê°€ì¤‘ì¹˜) ê°œìˆ˜\n",
    "\n",
    "lambda >> output, param=0 : ê°€ì¤‘ì¹˜ ì—†ëŠ” ë‹¨ìˆœ ë³€í™˜, ì´ë¯¸ì§€ë¥¼ efficientnetì´ ê¸°ëŒ€í•˜ëŠ” ì…ë ¥ ìŠ¤ì¼€ì¼/ë¶„í¬ë¡œ ë³€í™˜\n",
    "efficientnetb0 (Functional) >> output(none, 7, 7, 1280), param=4049571\n",
    "- EfficientNetB0ëŠ” ImageNetìœ¼ë¡œ ì‚¬ì „í•™ìŠµëœ CNN\n",
    "- 7*7 ê³µê°„ ê²©ìë¡œ ì¤„ì–´ë“¤ê³  ê° ìœ„ì¹˜ë§ˆë‹¤ 1280ë²¡í„°ê°€ ì¡´ì¬í•œë‹¤.\n",
    "- ë°±ë³¸ì„ ê³ ì •í•˜ê³   headë§Œ í•™ìŠµ\n",
    "\n",
    "global_average_pooling2d â†’ Output: (None, 1280), Params: 0\n",
    "- 7*7*1280 ì„ 1280ìœ¼ë¡œ ì••ì¶•í•˜ëŠ” ë‹¨ê³„, í‰ê· ë‚´ì„œ 1ê°œ ê°’ìœ¼ë¡œ ë§Œë“¦\n",
    "\n",
    "dropout (Dropout) â†’ Output: (None, 1280), Params: 0\n",
    "- ê³¼ì í•© ë°©ì§€\n",
    "\n",
    "dense (Dense) â†’ Output: (None, 1), Params: 1281\n",
    "- ì•…ì„±ì¼ í™•ë¥  ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "classes = np.array([0, 1])\n",
    "weights = compute_class_weight(\"balanced\", classes=classes, y=tr_df[\"target\"].values)\n",
    "class_weight = {0: weights[0], 1: weights[1]}\n",
    "class_weight\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", patience=3, mode=\"max\", restore_best_weights=True),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf82d8",
   "metadata": {},
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "ì˜ë£Œ ë°ì´í„°ëŠ” ë³´í†µ 0ê³¼ 1ë¡œ êµ¬ë¶„ë˜ëŠ”ê²Œ ì¼ë°˜ì ì„. ê·¸ë˜ì„œ í¬ê·€í•œ í´ë˜ìŠ¤ì— ë” í° íŒ¨ë„í‹°ë¥¼ ì¤€ë‹¤.\n",
    "classes = np.array([0, 1])\n",
    "weights = compute_class_weight(\n",
    "    \"balanced\",\n",
    "    classes=classes,\n",
    "    y=tr_df[\"target\"].values\n",
    ")\n",
    "balance : weight = n/(í´ë˜ìŠ¤ ìˆ˜)*(í•´ë‹¹ í´ë˜ìŠ¤ ìƒ˜í”Œ ìˆ˜)\n",
    "ì•…ì„± 1ê°œë¥¼ í‹€ë¦¬ë©´ ì •ìƒ 5ê°œ í‹€ë¦° ê²ƒì²˜ëŸ¼ ì·¨ê¸‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ea2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EfficientNet ì¼ë¶€ë§Œ unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86953ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "\n",
    "base = EfficientNetB0(\n",
    "    include_top=False,      # â— ë§ˆì§€ë§‰ ë¶„ë¥˜ê¸° ì œê±°\n",
    "    weights=\"imagenet\",     # â— ì´ë¯¸ ê³µë¶€í•œ ê°€ì¤‘ì¹˜ ì‚¬ìš©\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "base.trainable = True # ì „ì²´ë¥¼ íŠ¸ë£¨ë¡œ ë°”ê¿ˆ\n",
    "fine_tune_at = len(base.layers) - 40 # ìƒìœ„ 40ê°œ ë ˆì´ì–´ë§Œ í•™ìŠµ\n",
    "\n",
    "for layer in base.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in base.layers:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = False\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc7686e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lambda_1 (Lambda)           (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " efficientnetb0 (Functional)  (None, 7, 7, 1280)       4049571   \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1280)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,050,852\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "\n",
    "# 1) base ì •ì˜ (ì‚¬ì§„ ì˜ ë³´ëŠ” ëˆˆ)\n",
    "base = EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "base.trainable = False  # ì²˜ìŒì—” ì ê°€ë‘ê¸°\n",
    "\n",
    "# 2) model ì •ì˜ (ì´ê²Œ ì—†ì–´ì„œ ì—ëŸ¬ë‚œ ê±°!)\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input((224, 224, 3)),\n",
    "    layers.Lambda(preprocess_input),\n",
    "    base,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# 3) compile\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f40b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base.trainable = True\n",
    "\n",
    "fine_tune_at = len(base.layers) - 40\n",
    "for layer in base.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# BN ê³ ì •(ê¶Œì¥)\n",
    "for layer in base.layers:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c584b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6243427458617332, 1: 2.5105716523101016}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np \n",
    "\n",
    "classes = np.array([0,1])\n",
    "weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y = tr_df[\"target\"].values\n",
    ")\n",
    "\n",
    "class_weight = {0: weights[0], 1: weights[1]}\n",
    "\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa3d317",
   "metadata": {},
   "source": [
    "ë¶ˆê· í˜• ë³´ì • ì‘ì—…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "690aa6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_auc\", patience=3, mode=\"max\", restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_auc\", factor=0.5, patience=1, mode=\"max\", min_lr=1e-6\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d21d50",
   "metadata": {},
   "source": [
    "ì½œë°± ì„¤ì • (ê³¼ì í•© ë°©ì§€ + ìë™ ì¡°ì ˆ)\n",
    "\n",
    "EarlyStopping: ê²€ì¦ AUCê°€ ì•ˆ ì˜¤ë¥´ë©´ ë©ˆì¶¤\n",
    "\n",
    "ReduceLROnPlateau: ì„±ëŠ¥ ì •ì²´ ì‹œ í•™ìŠµë¥  ìë™ ê°ì†Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9628d0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 09:11:52.415465: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_22' with dtype double and shape [2]\n",
      "\t [[{{node Placeholder/_22}}]]\n",
      "2025-12-17 09:11:52.415888: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_12' with dtype resource\n",
      "\t [[{{node Placeholder/_12}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - ETA: 0s - loss: 0.6308 - auc: 0.6927 - recall: 0.6359 - precision: 0.2945"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 09:13:07.867737: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [1579]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2025-12-17 09:13:07.867985: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [1579]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 89s 416ms/step - loss: 0.6308 - auc: 0.6927 - recall: 0.6359 - precision: 0.2945 - val_loss: 0.4934 - val_auc: 0.8028 - val_recall: 0.5352 - val_precision: 0.4211 - lr: 1.0000e-05\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 86s 423ms/step - loss: 0.5049 - auc: 0.8397 - recall: 0.7987 - precision: 0.4231 - val_loss: 0.4011 - val_auc: 0.8274 - val_recall: 0.5246 - val_precision: 0.4502 - lr: 1.0000e-05\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 92s 453ms/step - loss: 0.4667 - auc: 0.8557 - recall: 0.8277 - precision: 0.4464 - val_loss: 0.3969 - val_auc: 0.8376 - val_recall: 0.5704 - val_precision: 0.4438 - lr: 1.0000e-05\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 93s 460ms/step - loss: 0.4428 - auc: 0.8716 - recall: 0.8426 - precision: 0.4697 - val_loss: 0.3772 - val_auc: 0.8468 - val_recall: 0.5599 - val_precision: 0.4663 - lr: 1.0000e-05\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 94s 465ms/step - loss: 0.4334 - auc: 0.8774 - recall: 0.8395 - precision: 0.4775 - val_loss: 0.3638 - val_auc: 0.8536 - val_recall: 0.5458 - val_precision: 0.4844 - lr: 1.0000e-05\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 95s 470ms/step - loss: 0.4184 - auc: 0.8857 - recall: 0.8504 - precision: 0.4835 - val_loss: 0.3541 - val_auc: 0.8581 - val_recall: 0.5493 - val_precision: 0.5253 - lr: 1.0000e-05\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 94s 463ms/step - loss: 0.4210 - auc: 0.8843 - recall: 0.8481 - precision: 0.4846 - val_loss: 0.3499 - val_auc: 0.8635 - val_recall: 0.5810 - val_precision: 0.5305 - lr: 1.0000e-05\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 93s 459ms/step - loss: 0.4014 - auc: 0.8937 - recall: 0.8661 - precision: 0.4946 - val_loss: 0.3481 - val_auc: 0.8671 - val_recall: 0.6056 - val_precision: 0.5443 - lr: 1.0000e-05\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 92s 454ms/step - loss: 0.4039 - auc: 0.8931 - recall: 0.8661 - precision: 0.4986 - val_loss: 0.3469 - val_auc: 0.8725 - val_recall: 0.6338 - val_precision: 0.5357 - lr: 1.0000e-05\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 95s 472ms/step - loss: 0.3869 - auc: 0.9028 - recall: 0.8786 - precision: 0.4998 - val_loss: 0.3355 - val_auc: 0.8759 - val_recall: 0.6056 - val_precision: 0.5658 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8052961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 10\n",
      "Best val AUC: 0.8759\n",
      "Best val Recall: 0.6338\n"
     ]
    }
   ],
   "source": [
    "# ê°€ì¥ ì¢‹ì•˜ë˜ ê²€ì¦ ì„±ëŠ¥ í™•ì¸\n",
    "best_epoch = np.argmax(history.history[\"val_auc\"]) + 1\n",
    "best_val_auc = max(history.history[\"val_auc\"])\n",
    "best_val_recall = max(history.history[\"val_recall\"])\n",
    "\n",
    "print(\"Best epoch:\", best_epoch)\n",
    "print(\"Best val AUC:\", round(best_val_auc, 4))\n",
    "print(\"Best val Recall:\", round(best_val_recall, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc48376f",
   "metadata": {},
   "source": [
    "ì´ë¯¸ì§€ ê¸°ë°˜ CNN ëª¨ë¸ì€ ê²€ì¦ ë°ì´í„°ì—ì„œ AUC 0.87ì˜ ë¶„ë¦¬ ì„±ëŠ¥ì„ ë³´ì˜€ìœ¼ë©°,\n",
    "ì•…ì„± ë³‘ë³€ì— ëŒ€í•œ ì¬í˜„ìœ¨ì€ ì•½ 60% ìˆ˜ì¤€\n",
    "\n",
    "ì‹¤ì œ ì•…ì„± 100ê°œ ì¤‘ 60ê°œë¥¼ ì œëŒ€ë¡œ ì¡ì•„ëƒˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f623bd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 09:29:11.196803: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [2024]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2025-12-17 09:29:11.197470: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [2024]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 17s 254ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# í™•ë¥ (ì•…ì„±=1) ë½‘ê¸°\n",
    "y_test_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "y_test_proba = model.predict(test_ds).ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed06e095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8600820926608038\n",
      "Precision: 0.38620689655172413\n",
      "Recall: 0.8549618320610687\n",
      "F1: 0.5320665083135392\n",
      "Confusion matrix:\n",
      " [[1097  534]\n",
      " [  57  336]]\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.67      0.79      1631\n",
      "           1       0.39      0.85      0.53       393\n",
      "\n",
      "    accuracy                           0.71      2024\n",
      "   macro avg       0.67      0.76      0.66      2024\n",
      "weighted avg       0.84      0.71      0.74      2024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thr = 0.2\n",
    "y_test_pred = (y_test_proba >= thr).astype(int)\n",
    "\n",
    "print(\"AUC:\", roc_auc_score(y_test_true, y_test_proba))\n",
    "print(\"Precision:\", precision_score(y_test_true, y_test_pred))\n",
    "print(\"Recall:\", recall_score(y_test_true, y_test_pred))\n",
    "print(\"F1:\", f1_score(y_test_true, y_test_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test_true, y_test_pred))\n",
    "print(\"\\nReport:\\n\", classification_report(y_test_true, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46ddda0",
   "metadata": {},
   "source": [
    "th = 0.2ìœ¼ë¡œ ì„¤ì •í•œë‹¤. ìµœì¢… accuracy 76%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44008a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "base.trainable = True\n",
    "\n",
    "fine_tune_last = 60\n",
    "fine_tune_at = len(base.layers) - fine_tune_last\n",
    "\n",
    "for layer in base.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in base.layers:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.traindable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "652bfafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),  # ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a2c87dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 09:34:17.764013: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype resource\n",
      "\t [[{{node Placeholder/_10}}]]\n",
      "2025-12-17 09:34:17.764385: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_13' with dtype resource\n",
      "\t [[{{node Placeholder/_13}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 95s 438ms/step - loss: 0.5710 - auc: 0.7982 - recall: 0.8316 - precision: 0.3584 - val_loss: 0.4009 - val_auc: 0.8821 - val_recall: 0.7430 - val_precision: 0.4658 - lr: 1.0000e-05\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 98s 487ms/step - loss: 0.5195 - auc: 0.8336 - recall: 0.8434 - precision: 0.3848 - val_loss: 0.3979 - val_auc: 0.8784 - val_recall: 0.7148 - val_precision: 0.4677 - lr: 1.0000e-05\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 102s 504ms/step - loss: 0.4920 - auc: 0.8520 - recall: 0.8387 - precision: 0.4020 - val_loss: 0.4021 - val_auc: 0.8823 - val_recall: 0.7570 - val_precision: 0.4584 - lr: 5.0000e-06\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 106s 524ms/step - loss: 0.4818 - auc: 0.8564 - recall: 0.8473 - precision: 0.4108 - val_loss: 0.3920 - val_auc: 0.8847 - val_recall: 0.7535 - val_precision: 0.4632 - lr: 5.0000e-06\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 108s 533ms/step - loss: 0.4737 - auc: 0.8591 - recall: 0.8661 - precision: 0.4150 - val_loss: 0.3861 - val_auc: 0.8871 - val_recall: 0.7535 - val_precision: 0.4703 - lr: 5.0000e-06\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 105s 521ms/step - loss: 0.4597 - auc: 0.8698 - recall: 0.8598 - precision: 0.4231 - val_loss: 0.3766 - val_auc: 0.8886 - val_recall: 0.7500 - val_precision: 0.4819 - lr: 5.0000e-06\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 108s 533ms/step - loss: 0.4608 - auc: 0.8663 - recall: 0.8598 - precision: 0.4196 - val_loss: 0.3682 - val_auc: 0.8898 - val_recall: 0.7465 - val_precision: 0.4919 - lr: 5.0000e-06\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 111s 548ms/step - loss: 0.4507 - auc: 0.8723 - recall: 0.8543 - precision: 0.4343 - val_loss: 0.3628 - val_auc: 0.8912 - val_recall: 0.7359 - val_precision: 0.5000 - lr: 5.0000e-06\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 106s 523ms/step - loss: 0.4472 - auc: 0.8734 - recall: 0.8598 - precision: 0.4408 - val_loss: 0.3549 - val_auc: 0.8915 - val_recall: 0.7254 - val_precision: 0.5112 - lr: 5.0000e-06\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 104s 516ms/step - loss: 0.4409 - auc: 0.8763 - recall: 0.8559 - precision: 0.4341 - val_loss: 0.3469 - val_auc: 0.8928 - val_recall: 0.7077 - val_precision: 0.5221 - lr: 5.0000e-06\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", patience=3, mode=\"max\", restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_auc\", factor=0.5, patience=1, mode=\"max\", min_lr=1e-6),\n",
    "]\n",
    "\n",
    "history_ft2 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e06b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.05),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomContrast(0.2),\n",
    "    tf.keras.layers.RandomBrightness(0.15),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad941d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = make_ds(tr_df, training=True)  # augment ìƒˆë¡œ ë°˜ì˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e054820e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 10\n",
      "Best val AUC: 0.8759\n",
      "Best val Recall (thr=0.5): 0.6338\n"
     ]
    }
   ],
   "source": [
    "# í•™ìŠµ ìƒíƒœ ì²´í¬ìš© (OK)\n",
    "best_epoch = np.argmax(history.history[\"val_auc\"]) + 1\n",
    "best_val_auc = max(history.history[\"val_auc\"])\n",
    "best_val_recall = max(history.history[\"val_recall\"])\n",
    "\n",
    "print(\"Best epoch:\", best_epoch)\n",
    "print(\"Best val AUC:\", round(best_val_auc, 4))\n",
    "print(\"Best val Recall (thr=0.5):\", round(best_val_recall, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53753750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "base.trainable = True\n",
    "\n",
    "fine_tune_last = 80\n",
    "fine_tune_at = len(base.layers) - fine_tune_last\n",
    "\n",
    "for layer in base.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in base.layers:\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.traindable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c285364",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),  # ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e8bfc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 09:54:26.460607: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_12' with dtype resource\n",
      "\t [[{{node Placeholder/_12}}]]\n",
      "2025-12-17 09:54:26.460942: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_13' with dtype resource\n",
      "\t [[{{node Placeholder/_13}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 104s 472ms/step - loss: 0.4598 - auc: 0.8658 - recall: 0.8449 - precision: 0.4251 - val_loss: 0.3564 - val_auc: 0.8801 - val_recall: 0.6937 - val_precision: 0.5368 - lr: 1.0000e-05\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 114s 563ms/step - loss: 0.4556 - auc: 0.8686 - recall: 0.8449 - precision: 0.4420 - val_loss: 0.3431 - val_auc: 0.8811 - val_recall: 0.6761 - val_precision: 0.5598 - lr: 1.0000e-05\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 109s 541ms/step - loss: 0.4433 - auc: 0.8736 - recall: 0.8387 - precision: 0.4492 - val_loss: 0.3388 - val_auc: 0.8832 - val_recall: 0.6796 - val_precision: 0.5727 - lr: 1.0000e-05\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 114s 564ms/step - loss: 0.4273 - auc: 0.8836 - recall: 0.8559 - precision: 0.4560 - val_loss: 0.3263 - val_auc: 0.8862 - val_recall: 0.6514 - val_precision: 0.5911 - lr: 1.0000e-05\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 119s 587ms/step - loss: 0.4182 - auc: 0.8893 - recall: 0.8489 - precision: 0.4734 - val_loss: 0.3196 - val_auc: 0.8878 - val_recall: 0.6479 - val_precision: 0.6053 - lr: 1.0000e-05\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 118s 586ms/step - loss: 0.4124 - auc: 0.8924 - recall: 0.8395 - precision: 0.4811 - val_loss: 0.3102 - val_auc: 0.8877 - val_recall: 0.6127 - val_precision: 0.6397 - lr: 1.0000e-05\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 116s 574ms/step - loss: 0.4031 - auc: 0.8987 - recall: 0.8301 - precision: 0.5077 - val_loss: 0.3167 - val_auc: 0.8929 - val_recall: 0.6655 - val_precision: 0.6077 - lr: 5.0000e-06\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 113s 557ms/step - loss: 0.3950 - auc: 0.9031 - recall: 0.8583 - precision: 0.5076 - val_loss: 0.3150 - val_auc: 0.8943 - val_recall: 0.6690 - val_precision: 0.6051 - lr: 5.0000e-06\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 113s 559ms/step - loss: 0.3972 - auc: 0.9010 - recall: 0.8567 - precision: 0.4950 - val_loss: 0.3113 - val_auc: 0.8957 - val_recall: 0.6655 - val_precision: 0.6156 - lr: 5.0000e-06\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 113s 560ms/step - loss: 0.3795 - auc: 0.9109 - recall: 0.8598 - precision: 0.5072 - val_loss: 0.3083 - val_auc: 0.8972 - val_recall: 0.6690 - val_precision: 0.6230 - lr: 5.0000e-06\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", patience=3, mode=\"max\", restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_auc\", factor=0.5, patience=1, mode=\"max\", min_lr=1e-6),\n",
    "]\n",
    "\n",
    "history_ft2 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8256323",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.05),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "    tf.keras.layers.RandomContrast(0.2),\n",
    "    tf.keras.layers.RandomBrightness(0.15),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "081b8862",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = make_ds(tr_df, training=True)  # augment ìƒˆë¡œ ë°˜ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4c01823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 10\n",
      "Best val AUC: 0.8759\n",
      "Best val Recall (thr=0.5): 0.6338\n"
     ]
    }
   ],
   "source": [
    "best_epoch = np.argmax(history.history[\"val_auc\"]) + 1\n",
    "best_val_auc = max(history.history[\"val_auc\"])\n",
    "best_val_recall = max(history.history[\"val_recall\"])\n",
    "\n",
    "print(\"Best epoch:\", best_epoch)\n",
    "print(\"Best val AUC:\", round(best_val_auc, 4))\n",
    "print(\"Best val Recall (thr=0.5):\", round(best_val_recall, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21c1e04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 2673345\n",
      "Trainable layers in base: 60 / 238\n",
      "Last 5 base trainable flags: [True, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "\n",
    "# ëª¨ë¸ ì •ì˜\n",
    "base = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
    "base.trainable = True\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input((224,224,3)),\n",
    "    layers.Lambda(preprocess_input),\n",
    "    base,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "# fine-tuning ì˜ˆì‹œ: ë§ˆì§€ë§‰ 60ê°œë§Œ í•™ìŠµ\n",
    "fine_tune_last = 60\n",
    "fine_tune_at = len(base.layers) - fine_tune_last\n",
    "for layer in base.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss=\"binary_crossentropy\",\n",
    ")\n",
    "\n",
    "# ===== ì§„ë‹¨ =====\n",
    "print(\"Trainable params:\",\n",
    "      np.sum([np.prod(v.shape) for v in model.trainable_weights]))\n",
    "\n",
    "print(\"Trainable layers in base:\",\n",
    "      sum([l.trainable for l in base.layers]), \"/\", len(base.layers))\n",
    "\n",
    "print(\"Last 5 base trainable flags:\",\n",
    "      [l.trainable for l in base.layers[-5:]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a6d1b",
   "metadata": {},
   "source": [
    "Trainable params: 2673345\n",
    "Trainable layers in base: 60 / 238\n",
    "Last 5 base trainable flags: [True, True, True, True, True]\n",
    "\n",
    "ì§€ê¸ˆì€ 267ë§Œê°œê°€ í•™ìŠµëŒ€ìƒ\n",
    "238ê°œ ë ˆì´ì–´ì¤‘ 60ê°œë§Œ í•™ìŠµ, ë‚˜ë¨¸ì§€ëŠ” ê³ ì • : ê³¼ì í•© ìœ„í—˜ ë‚®ìŒ\n",
    "\n",
    "AUC: 0.855025796315971\n",
    "Precision: 0.4294032023289665\n",
    "Recall: 0.7506361323155216\n",
    "F1: 0.5462962962962963\n",
    "\n",
    "threshold = 0.3 ìœ¼ë¡œ ë§ì¶”ëŠ”ê²Œ ì¬í˜„ìœ¨ì´ ì¢‹ìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "97945646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "augment = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.08),\n",
    "    tf.keras.layers.RandomZoom(0.15),\n",
    "    tf.keras.layers.RandomContrast(0.25),\n",
    "    tf.keras.layers.RandomBrightness(0.15),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a935c7da",
   "metadata": {},
   "source": [
    "ìˆ«ìëŠ” ì ì ˆíˆ ì ìš©  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b6aa104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH = 32\n",
    "\n",
    "# âœ… (A) ì´ë¯¸ì§€ ì½ê³  -> ë””ì½”ë”© -> ë¦¬ì‚¬ì´ì¦ˆ\n",
    "def decode_resize(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)   # jpg ê¸°ì¤€\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32)               # floatë¡œ ë³€í™˜\n",
    "    return img, label\n",
    "\n",
    "# âœ… (B) ë°ì´í„° ì¦ê°• (trainì¼ ë•Œë§Œ ì ìš©)\n",
    "augment = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.08),\n",
    "    tf.keras.layers.RandomZoom(0.15),\n",
    "    tf.keras.layers.RandomContrast(0.25),\n",
    "    tf.keras.layers.RandomBrightness(0.15),\n",
    "])\n",
    "\n",
    "# âœ… (C) df -> tf.data.Dataset ë§Œë“¤ì–´ì£¼ëŠ” í•¨ìˆ˜\n",
    "def make_ds(df_part, training=False):\n",
    "    paths = df_part[\"image_path\"].values\n",
    "    labels = df_part[\"target\"].values.astype(\"int32\")\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "    # trainì´ë©´ ì„ê¸°(ì…”í”Œ)\n",
    "    if training:\n",
    "        ds = ds.shuffle(2048, seed=42, reshuffle_each_iteration=True)\n",
    "\n",
    "    # ì´ë¯¸ì§€ ë¡œë”©/ë¦¬ì‚¬ì´ì¦ˆ\n",
    "    ds = ds.map(decode_resize, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    # trainì´ë©´ ì¦ê°• ì ìš©\n",
    "    if training:\n",
    "        ds = ds.map(lambda x, y: (augment(x, training=True), y),\n",
    "                    num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    # ë°°ì¹˜ + ë¯¸ë¦¬ ë¡œë“œ(prefetch)\n",
    "    ds = ds.batch(BATCH).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6822ece2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´ df í¬ê¸°: (10015, 9)\n",
      "ì•…ì„± ë¹„ìœ¨: 0.19510733899151272\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ğŸ”§ ê²½ë¡œ (ì—¬ê¸°ë§Œ ë„¤ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)\n",
    "META_PATH = Path(\"HAM10000_metadata.csv\")\n",
    "IMG_DIR = Path(\"image\")   # ì˜ˆ: HAM10000_images, HAM10000_images_part_1 ë“±\n",
    "\n",
    "# ë©”íƒ€ë°ì´í„° ë¡œë“œ\n",
    "df = pd.read_csv(META_PATH)\n",
    "\n",
    "# ì•…ì„±(1) / ì–‘ì„±(0) ë¼ë²¨ ë§Œë“¤ê¸°\n",
    "malignant = [\"mel\", \"bcc\", \"akiec\"]\n",
    "df[\"target\"] = df[\"dx\"].isin(malignant).astype(int)\n",
    "\n",
    "# ì´ë¯¸ì§€ ê²½ë¡œ ë§Œë“¤ê¸°\n",
    "df[\"image_path\"] = df[\"image_id\"].apply(lambda x: str(IMG_DIR / f\"{x}.jpg\"))\n",
    "\n",
    "# ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬í•˜ëŠ” ê²ƒë§Œ ì‚¬ìš©\n",
    "df = df[df[\"image_path\"].apply(lambda p: Path(p).exists())].reset_index(drop=True)\n",
    "\n",
    "print(\"ì „ì²´ df í¬ê¸°:\", df.shape)\n",
    "print(\"ì•…ì„± ë¹„ìœ¨:\", df[\"target\"].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "451072ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train / val / test í¬ê¸°: 6412 1579 2024\n",
      "train ì•…ì„± ë¹„ìœ¨: 0.19915782907049281\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "# 1ï¸âƒ£ test ë¶„ë¦¬ (20%)\n",
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(\n",
    "    gss.split(df, df[\"target\"], groups=df[\"lesion_id\"])\n",
    ")\n",
    "\n",
    "train_df = df.iloc[train_idx].copy()\n",
    "test_df  = df.iloc[test_idx].copy()\n",
    "\n",
    "# 2ï¸âƒ£ train â†’ train / val ë¶„ë¦¬ (trainì˜ 20% â†’ val)\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "tr_idx, val_idx = next(\n",
    "    gss2.split(train_df, train_df[\"target\"], groups=train_df[\"lesion_id\"])\n",
    ")\n",
    "\n",
    "tr_df  = train_df.iloc[tr_idx].copy()\n",
    "val_df = train_df.iloc[val_idx].copy()\n",
    "\n",
    "print(\"train / val / test í¬ê¸°:\",\n",
    "      len(tr_df), len(val_df), len(test_df))\n",
    "\n",
    "print(\"train ì•…ì„± ë¹„ìœ¨:\", tr_df[\"target\"].mean())\n",
    "\n",
    "\n",
    "train_ds = make_ds(tr_df, training=True)\n",
    "val_ds = make_ds(val_df, training=False)\n",
    "test_ds = make_ds(test_df, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5fa44091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6243427458617332, 1: 2.5105716523101016}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "classes = np.array([0, 1])\n",
    "\n",
    "weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=tr_df[\"target\"].values\n",
    ")\n",
    "\n",
    "class_weight = {0: weights[0], 1: weights[1]}\n",
    "class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23a99062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6c4bb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 10:15:20.539790: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype resource\n",
      "\t [[{{node Placeholder/_10}}]]\n",
      "2025-12-17 10:15:20.540228: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_22' with dtype double and shape [2]\n",
      "\t [[{{node Placeholder/_22}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - ETA: 0s - loss: 0.6348 - auc: 0.7106 - recall: 0.7659 - precision: 0.3002"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 10:16:46.392240: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [1579]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2025-12-17 10:16:46.392714: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [1579]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 102s 469ms/step - loss: 0.6348 - auc: 0.7106 - recall: 0.7659 - precision: 0.3002 - val_loss: 0.5384 - val_auc: 0.7853 - val_recall: 0.5880 - val_precision: 0.4073 - lr: 1.0000e-05\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 105s 520ms/step - loss: 0.5738 - auc: 0.7919 - recall: 0.8356 - precision: 0.3487 - val_loss: 0.4627 - val_auc: 0.8321 - val_recall: 0.5951 - val_precision: 0.4643 - lr: 1.0000e-05\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 102s 503ms/step - loss: 0.5336 - auc: 0.8218 - recall: 0.8387 - precision: 0.3798 - val_loss: 0.4265 - val_auc: 0.8500 - val_recall: 0.6232 - val_precision: 0.4917 - lr: 1.0000e-05\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 99s 490ms/step - loss: 0.5040 - auc: 0.8412 - recall: 0.8512 - precision: 0.4026 - val_loss: 0.3917 - val_auc: 0.8613 - val_recall: 0.6127 - val_precision: 0.5133 - lr: 1.0000e-05\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 100s 494ms/step - loss: 0.4858 - auc: 0.8510 - recall: 0.8348 - precision: 0.4151 - val_loss: 0.3662 - val_auc: 0.8681 - val_recall: 0.6127 - val_precision: 0.5559 - lr: 1.0000e-05\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 101s 498ms/step - loss: 0.4743 - auc: 0.8577 - recall: 0.8340 - precision: 0.4294 - val_loss: 0.3501 - val_auc: 0.8721 - val_recall: 0.5845 - val_precision: 0.5825 - lr: 1.0000e-05\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 100s 494ms/step - loss: 0.4642 - auc: 0.8633 - recall: 0.8316 - precision: 0.4457 - val_loss: 0.3416 - val_auc: 0.8778 - val_recall: 0.5951 - val_precision: 0.5768 - lr: 1.0000e-05\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 104s 515ms/step - loss: 0.4564 - auc: 0.8671 - recall: 0.8371 - precision: 0.4528 - val_loss: 0.3313 - val_auc: 0.8810 - val_recall: 0.5951 - val_precision: 0.6123 - lr: 1.0000e-05\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 107s 529ms/step - loss: 0.4479 - auc: 0.8706 - recall: 0.8191 - precision: 0.4487 - val_loss: 0.3243 - val_auc: 0.8861 - val_recall: 0.6056 - val_precision: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 103s 507ms/step - loss: 0.4370 - auc: 0.8785 - recall: 0.8324 - precision: 0.4598 - val_loss: 0.3186 - val_auc: 0.8887 - val_recall: 0.6092 - val_precision: 0.6291 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", patience=4, mode=\"max\", restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_auc\", factor=0.5, patience=2, mode=\"max\", min_lr=1e-6),\n",
    "]\n",
    "\n",
    "\n",
    "history_aug = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3b624a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'auc', 'recall', 'precision', 'val_loss', 'val_auc', 'val_recall', 'val_precision', 'lr'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_aug.history.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df80435c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 10\n",
      "Best val AUC: 0.8887\n",
      "Best val Recall: 0.6232\n",
      "Best val Precision: 0.6291\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "hist = history_aug.history\n",
    "best_epoch = int(np.argmax(hist[\"val_auc\"]) + 1)\n",
    "\n",
    "print(\"Best epoch:\", best_epoch)\n",
    "print(\"Best val AUC:\", round(max(hist[\"val_auc\"]), 4))\n",
    "print(\"Best val Recall:\", round(max(hist[\"val_recall\"]), 4))\n",
    "print(\"Best val Precision:\", round(max(hist[\"val_precision\"]), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a09306f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 14s 255ms/step\n",
      "val AUC: 0.8886752950133232\n",
      "val Precision@0.2: 0.4609053497942387\n",
      "val Recall@0.2: 0.7887323943661971\n",
      "val F1@0.2: 0.5818181818181818\n",
      "val Confusion:\n",
      " [[1033  262]\n",
      " [  60  224]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "y_val_true = np.concatenate([y for x, y in val_ds], axis=0)\n",
    "y_val_proba = model.predict(val_ds).ravel()\n",
    "\n",
    "thr = 0.3\n",
    "y_val_pred = (y_val_proba >= thr).astype(int)\n",
    "\n",
    "print(\"val AUC:\", roc_auc_score(y_val_true, y_val_proba))\n",
    "print(\"val Precision@0.2:\", precision_score(y_val_true, y_val_pred))\n",
    "print(\"val Recall@0.2:\", recall_score(y_val_true, y_val_pred))\n",
    "print(\"val F1@0.2:\", f1_score(y_val_true, y_val_pred))\n",
    "print(\"val Confusion:\\n\", confusion_matrix(y_val_true, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac870a5",
   "metadata": {},
   "source": [
    "<thresd = 0.2>\n",
    "AUC: 0.855025796315971 // auc : ëª¨ë¸ì´ ì•…ì„± í™˜ìë¥¼ ì–‘ì„± í™˜ìë³´ë‹¤ ë” ë†’ì€ ì ìˆ˜ë¡œ ì˜ êµ¬ë¶„í•˜ëŠ” ëŠ¥ë ¥, ë‹¨ì§€ ëª¨ë¸ì˜ ëŠ¥ë ¥ì„ ìˆ˜ì¹˜í™” í•œ ê²ƒ\n",
    "Precision: 0.4294032023289665\n",
    "Recall: 0.7506361323155216\n",
    "F1: 0.5462962962962963\n",
    "\n",
    "<epoch = 10>\n",
    "val AUC: 0.8932024579911905\n",
    "val Precision@0.2: 0.554016620498615\n",
    "val Recall@0.2: 0.704225352112676\n",
    "val F1@0.2: 0.6201550387596899\n",
    "\n",
    "epoch = 9ë¡œ ë‹¤ì‹œ í•™ìŠµí•  í•„ìš” ì—†ë‹¤. ë‹¨ì§€ ê· í˜•ì´ ë” ì¢‹ì•˜ë‹¤ëŠ” ì˜ë¯¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0ff4213a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 10:35:12.018537: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [2024]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2025-12-17 10:35:12.018745: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [2024]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 16s 245ms/step\n",
      "test AUC: 0.8612225285225974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.75      0.83      1631\n",
      "           1       0.43      0.80      0.56       393\n",
      "\n",
      "    accuracy                           0.76      2024\n",
      "   macro avg       0.69      0.77      0.70      2024\n",
      "weighted avg       0.84      0.76      0.78      2024\n",
      "\n",
      "confusion:\n",
      " [[1223  408]\n",
      " [  79  314]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 10:35:35.425602: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.465826: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,96]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.498439: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,144]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.515692: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,56,56,24]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.549256: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,144]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.593793: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,240]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.620482: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,28,28,40]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.645257: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,240]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.687684: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,480]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.705503: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,14,14,80]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.737348: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,480]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.753179: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,14,14,80]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.782854: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,480]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.817918: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,672]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.840165: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,14,14,112]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.874246: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,672]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.899083: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,14,14,112]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.931483: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,672]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.961588: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1152]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.978757: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,7,7,192]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:35.999265: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1152]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:36.015312: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,7,7,192]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:36.037278: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1152]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:36.057788: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,7,7,192]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:36.092279: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1152]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:42.378319: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:42.549148: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,96]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:42.727255: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,144]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:42.813060: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,56,56,24]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:42.970705: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,144]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:43.134555: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,240]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:43.200402: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,28,28,40]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:43.323503: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,240]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:43.498096: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,480]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:43.573015: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,14,14,80]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:43.704624: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,480]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:43.780751: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,14,14,80]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:43.903842: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,480]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:44.080296: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,672]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:44.150188: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,14,14,112]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:44.296020: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,672]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:44.369179: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,14,14,112]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:44.481876: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,672]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:44.634297: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1152]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:44.695227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,7,7,192]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:44.807830: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1152]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:44.888666: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,7,7,192]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:44.999953: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1152]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:45.093885: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,7,7,192]\n",
      "\t [[{{node inputs}}]]\n",
      "2025-12-17 10:35:45.205063: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1152]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 82). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: skin_cancer_savedmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: skin_cancer_savedmodel/assets\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import numpy as np \n",
    "\n",
    "# 1) test_dfê°€ ì´ë¯¸ ìˆë‹¤ë©´\n",
    "test_ds = make_ds(test_df, training=False)\n",
    "\n",
    "# 2) ë°”ë¡œ í‰ê°€\n",
    "y_test_true  = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "y_test_proba = model.predict(test_ds).ravel()\n",
    "\n",
    "thr = 0.3  # <- ë„¤ê°€ ìµœì¢… ì„ íƒí•œ ê°’ìœ¼ë¡œ ë°”ê¾¸ê¸°\n",
    "y_test_pred = (y_test_proba >= thr).astype(int)\n",
    "\n",
    "print(\"test AUC:\", roc_auc_score(y_test_true, y_test_proba))\n",
    "print(classification_report(y_test_true, y_test_pred))\n",
    "print(\"confusion:\\n\", confusion_matrix(y_test_true, y_test_pred))\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "tf.saved_model.save(model, \"skin_cancer_savedmodel\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5811a20d",
   "metadata": {},
   "source": [
    "test AUC : 0.87 ìœ ì§€, ê³¼ì í•© ì•„ë‹˜\n",
    "\n",
    "ì–‘ì„±ì´ë¼ê³  ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ì—ì„œ 92%ê°€ ì‹¤ì œ ì–‘ì„±\n",
    "ì‹¤ì œ ì–‘ì„± ì¤‘ì—ì„œ 82%ë¥¼ ì •í™•íˆ ë§ì¶¤\n",
    "\n",
    "ì•…ì„±ì´ë¼ê³  ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ì—ì„œ 49%ë§Œ ì‹¤ì œ ì•…ì„±\n",
    "ì‹¤ì œ ì•…ì„±ì˜ 72%ë¥¼ ìƒ‰ì¶œí•¨\n",
    "\n",
    "confusion :\n",
    "âœ… ì•…ì„± 393ëª… ì¤‘ 282ëª… íƒì§€ (Recall â‰ˆ 72%)\n",
    "âŒ 111ëª…ì€ ë†“ì¹¨(FN) â†’ ê°œì„  ì—¬ì§€\n",
    "âš ï¸ ì–‘ì„± 291ëª…ì´ ì•…ì„±ìœ¼ë¡œ ì˜¤íƒ(FP) â†’ ì¶”ê°€ ê²€ì‚¬ ëŒ€ìƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd96dd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Skin_Cancer_01.ipynb',\n",
       " 'hmnist_8_8_L.csv',\n",
       " 'logic_test_01.ipynb',\n",
       " 'hmnist_8_8_RGB.csv',\n",
       " '03-03',\n",
       " 'HAM10000_images_part_1',\n",
       " 'skin_cancer_savedmodel',\n",
       " 'HAM10000_metadata.csv',\n",
       " 'README.md',\n",
       " 'hmnist_28_28_RGB.csv',\n",
       " 'image',\n",
       " 'metadata_analysis.ipynb',\n",
       " 'Skin_Cancer.ipynb',\n",
       " 'hmnist_28_28_L.csv',\n",
       " 'HAM10000_clean.csv',\n",
       " 'HAM10000_images_part_2',\n",
       " 'cnn_training.ipynb']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "glob.glob(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "765a3e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 1) ëª¨ë¸ ì •ì˜\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = tf.keras.layers.Rescaling(1./255)(inputs)\n",
    "x = tf.keras.layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.MaxPooling2D()(x)\n",
    "x = tf.keras.layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# 2) compile\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[tf.keras.metrics.AUC(name=\"auc\"), \"accuracy\"]\n",
    ")\n",
    "\n",
    "# âœ… 3) (ì¤‘ìš”) ëª¨ë¸ì´ ì‹¤ì œë¡œ buildë˜ë„ë¡ í•œ ë²ˆ í˜¸ì¶œ/í•™ìŠµ\n",
    "# ì•„ë˜ ë‘˜ ì¤‘ í•˜ë‚˜ë§Œ í•˜ë©´ ë¨\n",
    "\n",
    "# (A) ë”ë¯¸ ì…ë ¥ìœ¼ë¡œ 1ë²ˆ í˜¸ì¶œ\n",
    "_ = model(tf.zeros((1, 224, 224, 3)))\n",
    "\n",
    "# (B) ë˜ëŠ” ì‹¤ì œ fitì„ 1epochë¼ë„ ëŒë¦¬ê¸°\n",
    "# model.fit(train_ds, validation_data=val_ds, epochs=1)\n",
    "\n",
    "# 4) ì €ì¥ (í™•ì¥ì .keras ê¶Œì¥)\n",
    "model.save(\"skin_cancer_model.keras\")\n",
    "print(\"saved!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6e591340",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.keras.models.load_model(\"skin_cancer_model.keras\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea28c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "prec, rec, thr_list = precision_recall_curve(y_val_true, y_val_proba)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(rec, prec)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"PR Curve (val)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f720b3",
   "metadata": {},
   "source": [
    "EfficientNet ê¸°ë°˜ CNN ëª¨ë¸ì„ í™œìš©í•˜ì—¬ í”¼ë¶€ ë³‘ë³€ì˜ ì•…ì„± ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•˜ì˜€ë‹¤. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ AUC 0.87ì„ ê¸°ë¡í•˜ì—¬ ì–‘Â·ì•…ì„± ë³‘ë³€ì„ ì•ˆì •ì ìœ¼ë¡œ êµ¬ë¶„í•  ìˆ˜ ìˆìŒì„ í™•ì¸í•˜ì˜€ë‹¤. íŠ¹íˆ ì•…ì„± ë³‘ë³€ì— ëŒ€í•´ ì¬í˜„ìœ¨ 0.72ë¥¼ ë‹¬ì„±í•˜ì—¬ ë¯¸íƒì„ ìµœì†Œí™”í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ëª¨ë¸ì„ ì„¤ê³„í•˜ì˜€ë‹¤. ë‹¤ë§Œ ì •ë°€ë„ëŠ” 0.49ë¡œ ì¼ë¶€ ì–‘ì„± ë³‘ë³€ì´ ì•…ì„±ìœ¼ë¡œ ì˜¤íƒë˜ëŠ” í•œê³„ê°€ ì¡´ì¬í•˜ë‚˜, ì´ëŠ” ì„ ë³„(screening) ëª©ì ì˜ ì˜ë£Œ AI íŠ¹ì„±ì„ ê³ ë ¤í•  ë•Œ í—ˆìš© ê°€ëŠ¥í•œ ìˆ˜ì¤€ìœ¼ë¡œ íŒë‹¨ë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "980ba58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 10:38:47.992116: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype resource\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2025-12-17 10:38:47.992518: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype resource\n",
      "\t [[{{node Placeholder/_10}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 22s 104ms/step - loss: 0.4565 - auc: 0.7003 - accuracy: 0.8016 - val_loss: 0.4613 - val_auc: 0.6908 - val_accuracy: 0.8201\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 22s 107ms/step - loss: 0.4602 - auc: 0.6953 - accuracy: 0.7954 - val_loss: 0.4442 - val_auc: 0.6914 - val_accuracy: 0.8201\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 22s 110ms/step - loss: 0.4509 - auc: 0.7155 - accuracy: 0.7988 - val_loss: 0.4414 - val_auc: 0.6875 - val_accuracy: 0.8201\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 25s 122ms/step - loss: 0.4484 - auc: 0.7179 - accuracy: 0.7993 - val_loss: 0.4375 - val_auc: 0.6885 - val_accuracy: 0.8201\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 28s 140ms/step - loss: 0.4493 - auc: 0.7189 - accuracy: 0.7988 - val_loss: 0.4403 - val_auc: 0.6865 - val_accuracy: 0.8201\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 31s 154ms/step - loss: 0.4470 - auc: 0.7203 - accuracy: 0.7968 - val_loss: 0.4359 - val_auc: 0.6848 - val_accuracy: 0.8201\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 30s 149ms/step - loss: 0.4457 - auc: 0.7219 - accuracy: 0.7962 - val_loss: 0.4337 - val_auc: 0.6867 - val_accuracy: 0.8201\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 27s 133ms/step - loss: 0.4467 - auc: 0.7190 - accuracy: 0.7969 - val_loss: 0.4379 - val_auc: 0.6886 - val_accuracy: 0.8201\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 28s 141ms/step - loss: 0.4483 - auc: 0.7185 - accuracy: 0.7998 - val_loss: 0.4363 - val_auc: 0.6870 - val_accuracy: 0.8201\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 26s 129ms/step - loss: 0.4444 - auc: 0.7272 - accuracy: 0.7994 - val_loss: 0.4335 - val_auc: 0.6882 - val_accuracy: 0.8201\n"
     ]
    }
   ],
   "source": [
    "ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"best_model.keras\",\n",
    "    monitor=\"val_auc\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[ckpt]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f9cba9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6913902759552002\n"
     ]
    }
   ],
   "source": [
    "print(max(history.history[\"val_auc\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3a1861d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    5135\n",
      "1    1277\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(tr_df[\"target\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "481c9e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "201/201 [==============================] - 22s 108ms/step - loss: 0.4402 - auc: 0.7364 - accuracy: 0.7993 - val_loss: 0.4325 - val_auc: 0.6951 - val_accuracy: 0.8201\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 21s 106ms/step - loss: 0.4411 - auc: 0.7329 - accuracy: 0.8010 - val_loss: 0.4357 - val_auc: 0.6883 - val_accuracy: 0.8201\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 20s 101ms/step - loss: 0.4437 - auc: 0.7292 - accuracy: 0.7996 - val_loss: 0.4452 - val_auc: 0.6910 - val_accuracy: 0.8201\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 22s 110ms/step - loss: 0.4471 - auc: 0.7237 - accuracy: 0.7976 - val_loss: 0.4377 - val_auc: 0.6876 - val_accuracy: 0.8201\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 26s 128ms/step - loss: 0.4432 - auc: 0.7281 - accuracy: 0.8055 - val_loss: 0.4428 - val_auc: 0.6871 - val_accuracy: 0.8201\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 26s 130ms/step - loss: 0.4440 - auc: 0.7238 - accuracy: 0.8066 - val_loss: 0.4344 - val_auc: 0.6927 - val_accuracy: 0.8201\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 26s 130ms/step - loss: 0.4418 - auc: 0.7339 - accuracy: 0.7980 - val_loss: 0.4355 - val_auc: 0.6867 - val_accuracy: 0.8201\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 27s 134ms/step - loss: 0.4380 - auc: 0.7410 - accuracy: 0.8015 - val_loss: 0.4340 - val_auc: 0.6902 - val_accuracy: 0.8201\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 28s 137ms/step - loss: 0.4386 - auc: 0.7373 - accuracy: 0.8027 - val_loss: 0.4317 - val_auc: 0.6928 - val_accuracy: 0.8201\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 27s 132ms/step - loss: 0.4437 - auc: 0.7313 - accuracy: 0.7976 - val_loss: 0.4367 - val_auc: 0.6905 - val_accuracy: 0.8201\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"best_model.keras\",\n",
    "    monitor=\"val_auc\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[ckpt]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "723f3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"best_model.keras\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
